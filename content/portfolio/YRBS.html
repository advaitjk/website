---
title: "Youth Risk Behavior Surveillance"
author: "Alessandro Angeletti"
date: "2020-09-18"
output:
  html_document:
    theme: cosmo
    highlight: breezedark
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: hide
categories:
- People Analytics
draft: false
image: images/portfolio/school.jpg
---



<div id="youth-risk-behavior-surveillance" class="section level1">
<h1>Youth Risk Behavior Surveillance</h1>
<p>Every two years, the Centers for Disease Control and Prevention conduct the YRBSS survey, where it takes data from high schoolers (9th through 12th grade), to analyze health patterns. We will work with a selected group of variables from a random sample of observations during one of the years the YRBSS was conducted.</p>
<div id="load-the-data" class="section level2">
<h2>Load the data</h2>
<p>First we load and inspect the data.</p>
<pre><code>## Rows: 13,583
## Columns: 13
## $ age                      &lt;int&gt; 14, 14, 15, 15, 15, 15, 15, 14, 15, 15, 15...
## $ gender                   &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;f...
## $ grade                    &lt;chr&gt; &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9...
## $ hispanic                 &lt;chr&gt; &quot;not&quot;, &quot;not&quot;, &quot;hispanic&quot;, &quot;not&quot;, &quot;not&quot;, &quot;n...
## $ race                     &lt;chr&gt; &quot;Black or African American&quot;, &quot;Black or Afr...
## $ height                   &lt;dbl&gt; NA, NA, 1.73, 1.60, 1.50, 1.57, 1.65, 1.88...
## $ weight                   &lt;dbl&gt; NA, NA, 84.37, 55.79, 46.72, 67.13, 131.54...
## $ helmet_12m               &lt;chr&gt; &quot;never&quot;, &quot;never&quot;, &quot;never&quot;, &quot;never&quot;, &quot;did n...
## $ text_while_driving_30d   &lt;chr&gt; &quot;0&quot;, NA, &quot;30&quot;, &quot;0&quot;, &quot;did not drive&quot;, &quot;did ...
## $ physically_active_7d     &lt;int&gt; 4, 2, 7, 0, 2, 1, 4, 4, 5, 0, 0, 0, 4, 7, ...
## $ hours_tv_per_school_day  &lt;chr&gt; &quot;5+&quot;, &quot;5+&quot;, &quot;5+&quot;, &quot;2&quot;, &quot;3&quot;, &quot;5+&quot;, &quot;5+&quot;, &quot;5...
## $ strength_training_7d     &lt;int&gt; 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 3, 0, 0, 7, ...
## $ school_night_hours_sleep &lt;chr&gt; &quot;8&quot;, &quot;6&quot;, &quot;&lt;5&quot;, &quot;6&quot;, &quot;9&quot;, &quot;8&quot;, &quot;9&quot;, &quot;6&quot;, &quot;...</code></pre>
<p>There are observations on 13 different variables, some categorical and some numerical.
Before we carried on with our analysis, we checked <code>skimr::skim()</code> for any missing values, summary statistics of numerical variables, and rough histograms.</p>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">yrbss</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">13583</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">13</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">8</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">gender</td>
<td align="right">12</td>
<td align="right">1.00</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">grade</td>
<td align="right">79</td>
<td align="right">0.99</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">hispanic</td>
<td align="right">231</td>
<td align="right">0.98</td>
<td align="right">3</td>
<td align="right">8</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">race</td>
<td align="right">2805</td>
<td align="right">0.79</td>
<td align="right">5</td>
<td align="right">41</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">helmet_12m</td>
<td align="right">311</td>
<td align="right">0.98</td>
<td align="right">5</td>
<td align="right">12</td>
<td align="right">0</td>
<td align="right">6</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">text_while_driving_30d</td>
<td align="right">918</td>
<td align="right">0.93</td>
<td align="right">1</td>
<td align="right">13</td>
<td align="right">0</td>
<td align="right">8</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">hours_tv_per_school_day</td>
<td align="right">338</td>
<td align="right">0.98</td>
<td align="right">1</td>
<td align="right">12</td>
<td align="right">0</td>
<td align="right">7</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">school_night_hours_sleep</td>
<td align="right">1248</td>
<td align="right">0.91</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">7</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age</td>
<td align="right">77</td>
<td align="right">0.99</td>
<td align="right">16.16</td>
<td align="right">1.26</td>
<td align="right">12.00</td>
<td align="right">15.00</td>
<td align="right">16.00</td>
<td align="right">17.00</td>
<td align="right">18.00</td>
<td align="left">▁▂▅▅▇</td>
</tr>
<tr class="even">
<td align="left">height</td>
<td align="right">1004</td>
<td align="right">0.93</td>
<td align="right">1.69</td>
<td align="right">0.10</td>
<td align="right">1.27</td>
<td align="right">1.60</td>
<td align="right">1.68</td>
<td align="right">1.78</td>
<td align="right">2.11</td>
<td align="left">▁▅▇▃▁</td>
</tr>
<tr class="odd">
<td align="left">weight</td>
<td align="right">1004</td>
<td align="right">0.93</td>
<td align="right">67.91</td>
<td align="right">16.90</td>
<td align="right">29.94</td>
<td align="right">56.25</td>
<td align="right">64.41</td>
<td align="right">76.20</td>
<td align="right">180.99</td>
<td align="left">▆▇▂▁▁</td>
</tr>
<tr class="even">
<td align="left">physically_active_7d</td>
<td align="right">273</td>
<td align="right">0.98</td>
<td align="right">3.90</td>
<td align="right">2.56</td>
<td align="right">0.00</td>
<td align="right">2.00</td>
<td align="right">4.00</td>
<td align="right">7.00</td>
<td align="right">7.00</td>
<td align="left">▆▂▅▃▇</td>
</tr>
<tr class="odd">
<td align="left">strength_training_7d</td>
<td align="right">1176</td>
<td align="right">0.91</td>
<td align="right">2.95</td>
<td align="right">2.58</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">3.00</td>
<td align="right">5.00</td>
<td align="right">7.00</td>
<td align="left">▇▂▅▂▅</td>
</tr>
</tbody>
</table>
<blockquote>
<p>From the above, we can conclude that all 13 variables have a lot of missing values</p>
</blockquote>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<p>We first started with analyzing the <code>weight</code> of participants in kilograms. We described the distribution of weights with visualization and summary statistics.</p>
<p><img src="/portfolio/YRBS_files/figure-html/eda_on_weight-1.png" width="672" /></p>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   29.94   56.25   64.41   67.91   76.20  180.99</code></pre>
<blockquote>
<p>The data for weight is missing for 1004 survey respondents. We have filtered them out before plotting the density plot above.</p>
<p>The distribution is skewed to the right as median weight (64.4 kgs) is less than the mean weight (67.9 kgs). It is so because we have one outlier (max weight = 181 kgs) pulling the average up.</p>
</blockquote>
<p>Next we tried to identify how the level of physical activity affects a high schooler’s weight. We created a rough plot quickly to visualize trends, identify strong associations, and develop research questions.</p>
<p><img src="/portfolio/YRBS_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<blockquote>
<p>One would expect a correlation between level of physical activity and weight of a person - higher physical activity should ideally imply a lower (read: healthier) weight, however, according to our data that is not the case. There seems to be roughly the same kind of distribution of weights across all physical activity levels i.e. irrespective of how active a set of people has been in the last 7 days, their weights are identical to another set which hasn’t been as active.</p>
</blockquote>
<p>Next we created a new variable <code>physical_3plus</code>, which will be <code>yes</code> if they are physically active for at least 3 days a week, and <code>no</code> otherwise.</p>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 2 x 3
##   physical_3plus count  prop
##   &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt;
## 1 no              4404 0.331
## 2 yes             8906 0.669</code></pre>
<p>Here we calculate a 95% confidence interval for the population proportion of high schoolers that are <em>NOT</em> active 3 or more days per week.</p>
<pre><code>## [1] &quot;95% confidence interval for high schoolers who are NOT active for 3 or more days per week is:  -0.007959 , 0.00803&quot;</code></pre>
<p>Next we created a boxplot of <code>physical_3plus</code> vs. <code>weight</code> to explore whether there is a relationship between these two variables.</p>
<p><img src="/portfolio/YRBS_files/figure-html/boxplot-1.png" width="672" /></p>
<pre><code>## # A tibble: 1 x 2
##   median_weight mean_weight
##           &lt;dbl&gt;       &lt;dbl&gt;
## 1          65.8        68.4</code></pre>
<pre><code>## # A tibble: 1 x 2
##   median_weight mean_weight
##           &lt;dbl&gt;       &lt;dbl&gt;
## 1          62.6        66.7</code></pre>
<blockquote>
<p>The boxplots are a little surprising as one would expect them to be the other way round i.e. people who are more physically active (‘yes’ or 3+ days a week) should have a lower median weight compared to people who are less active physically (‘no’ or &lt; 3 days a week)</p>
<p>One possible reason why this might be the case is that a lower weight does not necessarily mean a high schooler is healthier or more active. Other factors such as age, dietary habits, amount of sleep, etc could be influencing weight to a greater extent.</p>
</blockquote>
</div>
<div id="confidence-interval" class="section level2">
<h2>Confidence Interval</h2>
<p>The boxplots above show how the medians of the two distributions compare, however we can also compare the means of the distributions using either a confidence interval or a hypothesis test.</p>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 2 x 9
##   physical_3plus mean_weight sd_weight count se_weight t_critical
##   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;
## 1 no                    66.7      17.6  4404     0.266       1.96
## 2 yes                   68.4      16.5  8906     0.175       1.96
## # ... with 3 more variables: margin_of_error &lt;dbl&gt;, lower &lt;dbl&gt;, upper &lt;dbl&gt;</code></pre>
<blockquote>
<p>There is an observed difference of roughly 1.7 kg (68.4 - 66.7) in the mean weights, and we notice that the two confidence intervals do not overlap.</p>
</blockquote>
<p>It seems that the difference is at least 95% statistically significant. So we also conducted a hypothesis test to verify this.</p>
</div>
<div id="hypothesis-test-with-formula" class="section level2">
<h2>Hypothesis test with formula</h2>
<blockquote>
<p><code>Null Hypothesis (Ho)</code>: mean weight for those who exercise at least 3 times a week is the same as mean weight for those who don’t exercise as frequently</p>
<p><code>Alternative Hypothesis (H1)</code> : mean weights are different for those who exercise at least 3 times a week and those who don’t</p>
</blockquote>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  weight by physical_3plus
## t = -5.353, df = 7478.8, p-value = 0.00000008908
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.424441 -1.124728
## sample estimates:
##  mean in group no mean in group yes 
##          66.67389          68.44847</code></pre>
<pre><code>##  [1] &quot;statistic&quot;   &quot;parameter&quot;   &quot;p.value&quot;     &quot;conf.int&quot;    &quot;estimate&quot;   
##  [6] &quot;null.value&quot;  &quot;stderr&quot;      &quot;alternative&quot; &quot;method&quot;      &quot;data.name&quot;</code></pre>
<pre><code>## [1] 0.00000008907531</code></pre>
<blockquote>
<p>Since the p-value is very low (significantly less than 5%), we reject the null hypothesis. Therefore, the difference of 1.7kgs between the means of both samples wasn’t just by chance or sampling error.</p>
</blockquote>
</div>
<div id="hypothesis-test-with-infer" class="section level2">
<h2>Hypothesis test with <code>infer</code></h2>
<p>Next, we used a new function, <code>hypothesize</code>, which falls into the ‘infer’ workflow to conduct a hypothesis test.</p>
<pre><code>## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.77</code></pre>
<p>After we initialized the test, we needed to simulate the test on the null distribution.</p>
<pre><code>## # A tibble: 1,000 x 2
##    replicate   stat
##        &lt;int&gt;  &lt;dbl&gt;
##  1         1 -0.122
##  2         2 -0.149
##  3         3 -0.264
##  4         4 -0.104
##  5         5 -0.441
##  6         6  0.185
##  7         7 -0.485
##  8         8 -0.224
##  9         9  0.773
## 10        10 -0.119
## # ... with 990 more rows</code></pre>
<p>We can visualize this null distribution with the following code:</p>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/portfolio/YRBS_files/figure-html/unnamed-chunk-10-1.png" width="672" />
Next, visualised to see how many of these null permutations have a difference of at least <code>obs_stat</code> of 1.77?</p>
<p>We also calculated the p-value for your hypothesis test using the function <code>infer::get_p_value()</code>.</p>
<p><img src="/portfolio/YRBS_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
<blockquote>
<p>Since p-value is ~0, the null hypothesis is <strong>REJECTED</strong></p>
</blockquote>
</div>
</div>
